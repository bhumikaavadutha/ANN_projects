{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b245d70-6a42-4221-8712-4843f8981363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b712815d-ef79-432f-b5a3-2d3a284227ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Accuracy: 1.00, Loss: 0.00\n",
      "Validation Accuracy: 1.00\n",
      "Testing Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Paths to the folders\n",
    "train_folder = '/home/bhumika-avadutha/Desktop/train'\n",
    "val_folder = '/home/bhumika-avadutha/Desktop/valid'\n",
    "test_folder = '/home/bhumika-avadutha/Desktop/test'\n",
    "\n",
    "# Load training data\n",
    "X_train, y_train = [], []\n",
    "for file in os.listdir(train_folder):\n",
    "    img_path = os.path.join(train_folder, file)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (32, 32))  # Resize the image\n",
    "        img = img.flatten()  # Flatten the image into a 1D array\n",
    "        X_train.append(img)\n",
    "        y_train.append(1)  # Assign class label 1\n",
    "    else:\n",
    "        print(f\"Error reading file {file}\")\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Initialize weights and bias\n",
    "weights = np.random.rand(X_train.shape[1])\n",
    "bias = 0\n",
    "\n",
    "# Set learning rate and number of iterations\n",
    "learning_rate = 0.01\n",
    "n_iters = 1\n",
    "\n",
    "# Train the model\n",
    "for _ in range(n_iters):\n",
    "    for i in range(len(X_train)):\n",
    "        x_i = X_train[i]\n",
    "        y_i = y_train[i]\n",
    "        # Calculate the predicted output\n",
    "        predicted = np.where(np.dot(x_i, weights) + bias >= 0, 1, -1)\n",
    "        # Update weights and bias\n",
    "        update = learning_rate * (y_i - predicted)\n",
    "        weights += update * x_i\n",
    "        bias += update\n",
    "    \n",
    "    # Calculate accuracy and loss\n",
    "    predictions = np.where(np.dot(X_train, weights) + bias >= 0, 1, -1)\n",
    "    accuracy = np.mean(predictions == y_train)\n",
    "    loss = np.mean((predictions - y_train) ** 2)\n",
    "    print(f'Iteration {_+1}, Accuracy: {accuracy:.2f}, Loss: {loss:.2f}')\n",
    "\n",
    "# Save the trained model\n",
    "np.save('weights.npy', weights)\n",
    "np.save('bias.npy', bias)\n",
    "\n",
    "# Load validation data\n",
    "X_val, y_val = [], []\n",
    "for file in os.listdir(val_folder):\n",
    "    img_path = os.path.join(val_folder, file)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (32, 32))  # Resize the image\n",
    "        img = img.flatten()  # Flatten the image into a 1D array\n",
    "        X_val.append(img)\n",
    "        y_val.append(1)  # Assign class label 1\n",
    "    else:\n",
    "        print(f\"Error reading file {file}\")\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# Load the trained model\n",
    "weights = np.load('weights.npy')\n",
    "bias = np.load('bias.npy')\n",
    "\n",
    "# Make predictions on validation set\n",
    "predictions = np.where(np.dot(X_val, weights) + bias >= 0, 1, -1)\n",
    "val_accuracy = np.mean(predictions == y_val)\n",
    "print(f'Validation Accuracy: {val_accuracy:.2f}')\n",
    "\n",
    "# Load test data\n",
    "X_test, y_test = [], []\n",
    "for file in os.listdir(test_folder):\n",
    "    img_path = os.path.join(test_folder, file)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (32, 32))  # Resize the image\n",
    "        img = img.flatten()  # Flatten the image into a 1D array\n",
    "        X_test.append(img)\n",
    "        y_test.append(1)  # Assign class label 1\n",
    "    else:\n",
    "        print(f\"Error reading file {file}\")\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Make predictions on testing set\n",
    "predictions = np.where(np.dot(X_test, weights) + bias >= 0, 1, -1)\n",
    "test_accuracy = np.mean(predictions == y_test)\n",
    "print(f'Testing Accuracy: {test_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d0abd6-a24b-4504-873a-e98712d8d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e6d7825-6d8b-44e1-8112-8b81fa014e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 images for training.\n",
      "Found 40 images for validation.\n",
      "Found 40 images for testing.\n",
      "Model with L2 regularization:\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhumika-avadutha/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.4824 - loss: 1.3354 - val_accuracy: 0.3750 - val_loss: 1.0442\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 11:38:51.946934: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "2024-08-20 11:38:52.010362: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/home/bhumika-avadutha/.local/lib/python3.10/site-packages/keras/src/callbacks/early_stopping.py:155: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5281 - loss: 1.1493 - val_accuracy: 0.5500 - val_loss: 1.0005\n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5887 - loss: 1.0681  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 11:38:52.306920: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5892 - loss: 1.0663 - val_accuracy: 0.6750 - val_loss: 0.9281\n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6046 - loss: 1.0261 - val_accuracy: 0.9500 - val_loss: 0.8297\n",
      "Epoch 8/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6006 - loss: 0.9891  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 11:38:52.740661: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6025 - loss: 0.9854 - val_accuracy: 1.0000 - val_loss: 0.7095\n",
      "Epoch 10/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.6690\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.7082 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6583 - loss: 11.6514 \n",
      "Training accuracy: 1.0\n",
      "Validation accuracy: 1.0\n",
      "Testing accuracy with L2 regularization: 0.675000011920929\n",
      "\n",
      "Model with Dropout:\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhumika-avadutha/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5226 - loss: 0.9402 - val_accuracy: 0.2250 - val_loss: 0.7899\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5903 - loss: 0.7497 - val_accuracy: 0.5000 - val_loss: 0.6893\n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6065 - loss: 0.7958 - val_accuracy: 0.9250 - val_loss: 0.4963\n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6730 - loss: 0.6574 - val_accuracy: 0.7750 - val_loss: 0.5795\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 11:38:55.435952: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6318 - loss: 0.6702 - val_accuracy: 0.5000 - val_loss: 0.7292\n",
      "Epoch 10/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9646 - loss: 0.4463\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9187 - loss: 0.5024 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7604 - loss: 11.3398 \n",
      "Training accuracy: 0.9750000238418579\n",
      "Validation accuracy: 0.925000011920929\n",
      "Testing accuracy with Dropout: 0.75\n",
      "\n",
      "Model with Batch Normalization:\n",
      "Epoch 1/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.5423 - loss: 0.8953 - val_accuracy: 0.9750 - val_loss: 0.4930\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5351 - loss: 0.8582 - val_accuracy: 0.9750 - val_loss: 0.5237\n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5702 - loss: 0.8067 - val_accuracy: 0.9500 - val_loss: 0.5318\n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5843 - loss: 0.7400 - val_accuracy: 0.9750 - val_loss: 0.4966\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9278 - loss: 0.5381\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9729 - loss: 0.4931 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9187 - loss: 3.1963 \n",
      "Training accuracy: 0.9281250238418579\n",
      "Validation accuracy: 0.9750000238418579\n",
      "Testing accuracy with Batch Normalization: 0.925000011920929\n",
      "\n",
      "Model with Early Stopping:\n",
      "Epoch 1/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4816 - loss: 0.9244 - val_accuracy: 0.5000 - val_loss: 0.7007\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5611 - loss: 0.7668 - val_accuracy: 0.7250 - val_loss: 0.6481\n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5745 - loss: 0.7429 - val_accuracy: 0.5750 - val_loss: 0.6779\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3509 - loss: 0.7703\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5104 - loss: 0.7000 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2875 - loss: 62.6092 \n",
      "Training accuracy: 0.3656249940395355\n",
      "Validation accuracy: 0.5\n",
      "Testing accuracy with Early Stopping: 0.2750000059604645\n",
      "\n",
      "Final accuracies:\n",
      "L2 Regularization - Training: 1.0, Validation: 1.0, Testing: 0.675000011920929\n",
      "Dropout - Training: 0.9750000238418579, Validation: 0.925000011920929, Testing: 0.75\n",
      "Batch Normalization - Training: 0.9281250238418579, Validation: 0.9750000238418579, Testing: 0.925000011920929\n",
      "Early Stopping - Training: 0.9281250238418579, Validation: 0.9750000238418579, Testing: 0.925000011920929\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "train_directory = \"/home/bhumika-avadutha/Desktop/train\"\n",
    "valid_directory = \"/home/bhumika-avadutha/Desktop/valid\"\n",
    "test_directory = \"/home/bhumika-avadutha/Desktop/test\"\n",
    "image_width, image_height = 28, 28  # Image dimensions\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Initialize lists to hold data and labels\n",
    "train_data, train_labels = [], []\n",
    "valid_data, valid_labels = [], []\n",
    "test_data, test_labels = [], []\n",
    "\n",
    "# Load and preprocess images for training\n",
    "directory = train_directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        img_path = os.path.join(directory, filename)\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=(image_width, image_height))\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        train_data.append(img_array)\n",
    "        train_labels.append(0)  # Assuming all images are of the same class (e.g., class 0)\n",
    "\n",
    "# Load and preprocess images for validation\n",
    "directory = valid_directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        img_path = os.path.join(directory, filename)\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=(image_width, image_height))\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        valid_data.append(img_array)\n",
    "        valid_labels.append(0)  # Assuming all images are of the same class (e.g., class 0)\n",
    "\n",
    "# Load and preprocess images for testing\n",
    "directory = test_directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        img_path = os.path.join(directory, filename)\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=(image_width, image_height))\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        test_data.append(img_array)\n",
    "        test_labels.append(0)  # Assuming all images are of the same class (e.g., class 0)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "train_data = np.array(train_data)\n",
    "train_labels = np.array(train_labels)\n",
    "valid_data = np.array(valid_data)\n",
    "valid_labels = np.array(valid_labels)\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Print number of images found\n",
    "print(f\"Found {len(train_data)} images for training.\")\n",
    "print(f\"Found {len(valid_data)} images for validation.\")\n",
    "print(f\"Found {len(test_data)} images for testing.\")\n",
    "\n",
    "# Set up data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Set up data generator for training\n",
    "train_generator = train_datagen.flow(\n",
    "    x=train_data,\n",
    "    y=train_labels,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow(\n",
    "    x=valid_data,\n",
    "    y=valid_labels,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False  # No need to shuffle validation data\n",
    ")\n",
    "\n",
    "train_accuracies = []\n",
    "valid_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Model building and training with L2 regularization\n",
    "print(\"Model with L2 regularization:\")\n",
    "model_l2 = Sequential([\n",
    "    Flatten(input_shape=(image_width, image_height, 3)),  # input layer\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),  # hidden layer with L2 regularization\n",
    "    BatchNormalization(),  # batch normalization layer\n",
    "    Dropout(0.5),  # dropout layer for regularization\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),  # additional hidden layer with L2 regularization\n",
    "    BatchNormalization(),  # batch normalization layer\n",
    "    Dropout(0.3),  # dropout layer for regularization\n",
    "    Dense(1, activation='sigmoid')  # output layer, sigmoid for binary classification\n",
    "])\n",
    "\n",
    "model_l2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model with L2 regularization\n",
    "history_l2 = model_l2.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=len(valid_generator),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model with L2 regularization on training data\n",
    "train_loss_l2, train_accuracy_l2 = model_l2.evaluate(train_generator, steps=len(train_generator))\n",
    "\n",
    "# Evaluate the model with L2 regularization on validation data\n",
    "valid_loss_l2, valid_accuracy_l2 = model_l2.evaluate(valid_generator, steps=len(valid_generator))\n",
    "\n",
    "# Evaluate the model with L2 regularization on testing data\n",
    "test_loss_l2, test_accuracy_l2 = model_l2.evaluate(test_data, test_labels)\n",
    "\n",
    "print(f'Training accuracy: {train_accuracy_l2}')\n",
    "print(f'Validation accuracy: {valid_accuracy_l2}')\n",
    "print(f'Testing accuracy with L2 regularization: {test_accuracy_l2}')\n",
    "\n",
    "# Store accuracies\n",
    "train_accuracies.append(train_accuracy_l2)\n",
    "valid_accuracies.append(valid_accuracy_l2)\n",
    "test_accuracies.append(test_accuracy_l2)\n",
    "\n",
    "# Model building and training with Dropout\n",
    "print(\"\\nModel with Dropout:\")\n",
    "model_dropout = Sequential([\n",
    "    Flatten(input_shape=(image_width, image_height, 3)),  # input layer\n",
    "    Dense(128, activation='relu'),  # hidden layer\n",
    "    BatchNormalization(),  # batch normalization layer\n",
    "    Dropout(0.5),  # dropout layer\n",
    "    Dense(64, activation='relu'),  # additional hidden layer\n",
    "    BatchNormalization(),  # batch normalization layer\n",
    "    Dropout(0.3),  \n",
    "    Dense(1, activation='sigmoid')  # output layer, sigmoid for binary classification\n",
    "])\n",
    "\n",
    "model_dropout.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model with Dropout\n",
    "history_dropout = model_dropout.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=len(valid_generator),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model with Dropout on training data\n",
    "train_loss_dropout, train_accuracy_dropout = model_dropout.evaluate(train_generator, steps=len(train_generator))\n",
    "\n",
    "# Evaluate the model with Dropout on validation data\n",
    "valid_loss_dropout, valid_accuracy_dropout = model_dropout.evaluate(valid_generator, steps=len(valid_generator))\n",
    "\n",
    "# Evaluate the model with Dropout on testing data\n",
    "test_loss_dropout, test_accuracy_dropout = model_dropout.evaluate(test_data, test_labels)\n",
    "\n",
    "\n",
    "print(f'Training accuracy: {train_accuracy_dropout}')\n",
    "print(f'Validation accuracy: {valid_accuracy_dropout}')\n",
    "print(f'Testing accuracy with Dropout: {test_accuracy_dropout}')\n",
    "\n",
    "\n",
    "# Store accuracies\n",
    "train_accuracies.append(train_accuracy_dropout)\n",
    "valid_accuracies.append(valid_accuracy_dropout)\n",
    "test_accuracies.append(test_accuracy_dropout)\n",
    "\n",
    "# Model building and training with Batch Normalization\n",
    "print(\"\\nModel with Batch Normalization:\")\n",
    "model_batchnorm = Sequential([\n",
    "    Flatten(input_shape=(image_width, image_height, 3)),  \n",
    "    Dense(128, activation='relu'),  # hidden layer\n",
    "    BatchNormalization(),  # batch normalization layer\n",
    "    Dropout(0.5),  # dropout layer\n",
    "    Dense(64, activation='relu'), \n",
    "    BatchNormalization(), \n",
    "    Dropout(0.3),  \n",
    "    Dense(1, activation='sigmoid')  # output layer, sigmoid for binary classification\n",
    "])\n",
    "\n",
    "model_batchnorm.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model with Batch Normalization\n",
    "history_batchnorm = model_batchnorm.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=len(valid_generator),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model with Batch Normalization on training data\n",
    "train_loss_batchnorm, train_accuracy_batchnorm = model_batchnorm.evaluate(train_generator, steps=len(train_generator))\n",
    "\n",
    "# Evaluate the model with Batch Normalization on validation data\n",
    "valid_loss_batchnorm, valid_accuracy_batchnorm = model_batchnorm.evaluate(valid_generator, steps=len(valid_generator))\n",
    "\n",
    "# Evaluate the model with Batch Normalization on testing data\n",
    "test_loss_batchnorm, test_accuracy_batchnorm = model_batchnorm.evaluate(test_data, test_labels)\n",
    "print(f'Training accuracy: {train_accuracy_batchnorm}')\n",
    "print(f'Validation accuracy: {valid_accuracy_batchnorm}')\n",
    "print(f'Testing accuracy with Batch Normalization: {test_accuracy_batchnorm}')\n",
    "\n",
    "# Store accuracies\n",
    "train_accuracies.append(train_accuracy_batchnorm)\n",
    "valid_accuracies.append(valid_accuracy_batchnorm)\n",
    "test_accuracies.append(test_accuracy_batchnorm)\n",
    "\n",
    "# Model building and training with Early Stopping\n",
    "\n",
    "print(\"\\nModel with Early Stopping:\")\n",
    "model_earlystop = Sequential([\n",
    "    Flatten(input_shape=(image_width, image_height, 3)),  # input layer\n",
    "    Dense(128, activation='relu'),  # hidden layer\n",
    "    BatchNormalization(),  # batch normalization layer\n",
    "    Dropout(0.5),  # dropout layer\n",
    "    Dense(64, activation='relu'),  # additional hidden layer\n",
    "    BatchNormalization(),  # batch normalization layer\n",
    "    Dropout(0.3),  # dropout layer\n",
    "    Dense(1, activation='sigmoid')  # output layer, sigmoid for binary classification\n",
    "])\n",
    "\n",
    "model_earlystop.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model with Early Stopping\n",
    "history_earlystop = model_earlystop.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=len(valid_generator),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model with Early Stopping on training data\n",
    "train_loss_earlystop, train_accuracy_earlystop = model_earlystop.evaluate(train_generator, steps=len(train_generator))\n",
    "\n",
    "# Evaluate the model with Early Stopping on validation data\n",
    "valid_loss_earlystop, valid_accuracy_earlystop = model_earlystop.evaluate(valid_generator, steps=len(valid_generator))\n",
    "\n",
    "# Evaluate the model with Early Stopping on testing data\n",
    "test_loss_earlystop, test_accuracy_earlystop = model_earlystop.evaluate(test_data, test_labels)\n",
    "\n",
    "print(f'Training accuracy: {train_accuracy_earlystop}')\n",
    "print(f'Validation accuracy: {valid_accuracy_earlystop}')\n",
    "print(f'Testing accuracy with Early Stopping: {test_accuracy_earlystop}')\n",
    "\n",
    "# Store accuracies\n",
    "train_accuracies.append(train_accuracy_batchnorm)\n",
    "valid_accuracies.append(valid_accuracy_batchnorm)\n",
    "test_accuracies.append(test_accuracy_batchnorm)\n",
    "\n",
    "# Print final accuracies\n",
    "print(\"\\nFinal accuracies:\")\n",
    "print(f'L2 Regularization - Training: {train_accuracies[0]}, Validation: {valid_accuracies[0]}, Testing: {test_accuracies[0]}')\n",
    "print(f'Dropout - Training: {train_accuracies[1]}, Validation: {valid_accuracies[1]}, Testing: {test_accuracies[1]}')\n",
    "print(f'Batch Normalization - Training: {train_accuracies[2]}, Validation: {valid_accuracies[2]}, Testing: {test_accuracies[2]}')\n",
    "print(f'Early Stopping - Training: {train_accuracies[3]}, Validation: {valid_accuracies[3]}, Testing: {test_accuracies[3]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0d6522-8bd8-49d3-ac38-cfe231bdd3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "494c97f5-fd8d-4fe4-8d1e-7070123fd584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy =99.69%\n",
      "validate accuracy = 100.00%\n",
      "Test Accuracy = 100.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Directory paths\n",
    "train_dir = '/home/bhumika-avadutha/Desktop/train/'\n",
    "valid_dir = '/home/bhumika-avadutha/Desktop/valid/'\n",
    "test_dir = '/home/bhumika-avadutha/Desktop/test/'\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "num_features = None\n",
    "weights = None\n",
    "bias = None\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Training and evaluation in a single loop\n",
    "for epoch in range(epochs):\n",
    "    # Read training data\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for filename in os.listdir(train_dir):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust file extensions as per your images\n",
    "            file_path = os.path.join(train_dir, filename)\n",
    "            img = Image.open(file_path)\n",
    "            img = img.resize((100, 100)).convert('L')  # Resize and convert to grayscale ('L' mode)\n",
    "            img_array = np.array(img)\n",
    "            X_train.append(img_array.flatten())  # Flatten image into 1D array\n",
    "            # Assuming the label is encoded in the filename or directory structure\n",
    "            label = 1 if 'class1' in filename else 0  # Adjust based on your data\n",
    "            y_train.append(label)\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    # Check if X_train is empty or has unexpected structure\n",
    "    if X_train.shape[0] == 0 or X_train.ndim != 2 or X_train.shape[1] < 1:\n",
    "        print(f\"Warning: X_train is empty or has unexpected structure in epoch {epoch + 1}. Skipping epoch.\")\n",
    "        continue\n",
    "    \n",
    "    # Initialize weights and bias on first epoch\n",
    "    if epoch == 0:\n",
    "        num_features = X_train.shape[1]\n",
    "        weights = np.zeros(num_features)\n",
    "        bias = 0.0\n",
    "    \n",
    "    # Read validation data\n",
    "    X_valid = []\n",
    "    y_valid = []\n",
    "    for filename in os.listdir(valid_dir):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust file extensions as per your images\n",
    "            file_path = os.path.join(valid_dir, filename)\n",
    "            img = Image.open(file_path)\n",
    "            img = img.resize((100, 100)).convert('L')  # Resize and convert to grayscale ('L' mode)\n",
    "            img_array = np.array(img)\n",
    "            X_valid.append(img_array.flatten())  # Flatten image into 1D array\n",
    "            # Assuming the label is encoded in the filename or directory structure\n",
    "            label = 1 if 'class1' in filename else 0  # Adjust based on your data\n",
    "            y_valid.append(label)\n",
    "    X_valid = np.array(X_valid)\n",
    "    y_valid = np.array(y_valid)\n",
    "    \n",
    "    # Read test data\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for filename in os.listdir(test_dir):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust file extensions as per your images\n",
    "            file_path = os.path.join(test_dir, filename)\n",
    "            img = Image.open(file_path)\n",
    "            img = img.resize((100, 100)).convert('L')  # Resize and convert to grayscale ('L' mode)\n",
    "            img_array = np.array(img)\n",
    "            X_test.append(img_array.flatten())  # Flatten image into 1D array\n",
    "            # Assuming the label is encoded in the filename or directory structure\n",
    "            label = 1 if 'class1' in filename else 0  # Adjust based on your data\n",
    "            y_test.append(label)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # Training loop\n",
    "    correct_train = 0\n",
    "    for i in range(len(X_train)):\n",
    "        x = X_train[i]\n",
    "        y_true = y_train[i]\n",
    "        \n",
    "        # Predict\n",
    "        linear_output = np.dot(weights, x) + bias\n",
    "        y_pred = 1 if linear_output >= 0 else 0\n",
    "        \n",
    "        # Update weights and bias if prediction is incorrect\n",
    "        if y_true != y_pred:\n",
    "            if y_true == 1:\n",
    "                weights += learning_rate * x\n",
    "                bias += learning_rate\n",
    "            else:\n",
    "                weights -= learning_rate * x\n",
    "                bias -= learning_rate\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        if y_true == y_pred:\n",
    "            correct_train += 1\n",
    "        train_accuracy = correct_train / len(X_train)\n",
    "    print(f\"train accuracy ={train_accuracy:.2%}\")   \n",
    "    # Validation accuracy\n",
    "    correct_valid = 0\n",
    "    for i in range(len(X_valid)):\n",
    "        x = X_valid[i]\n",
    "        y_true = y_valid[i]\n",
    "        linear_output = np.dot(weights, x) + bias\n",
    "        y_pred = 1 if linear_output >= 0 else 0\n",
    "        if y_true == y_pred:\n",
    "            correct_valid += 1\n",
    "    validation_accuracy = correct_valid / len(X_valid)\n",
    "    \n",
    "# print(f\"Epoch {epoch + 1}: Train Accuracy = {train_accuracy:.2%}, Validation Accuracy = {validation_accuracy:.2%}\")\n",
    "\n",
    "    print(f\"validate accuracy = {validation_accuracy:.2%}\")\n",
    "\n",
    "\n",
    "# Test accuracy\n",
    "    correct_test = 0\n",
    "    for i in range(len(X_test)):\n",
    "       x = X_test[i]\n",
    "       y_true = y_test[i]\n",
    "       linear_output = np.dot(weights, x) + bias\n",
    "       y_pred = 1 if linear_output >= 0 else 0\n",
    "       if y_true == y_pred:\n",
    "        correct_test += 1\n",
    "    test_accuracy = correct_test / len(X_test)\n",
    "\n",
    "    print(f\"Test Accuracy = {test_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ffe07b-ce4f-4ee7-bc9d-098f7679d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8a5577c-22c4-4027-bc78-46d980fed82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with optimizer: adam\n",
      "Epoch 1/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - accuracy: 0.5386 - loss: 0.8402 - val_accuracy: 0.7250 - val_loss: 0.7087\n",
      "Epoch 2/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.5418 - loss: 0.7398 - val_accuracy: 0.6000 - val_loss: 1.0652\n",
      "Epoch 3/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.5521 - loss: 0.6863 - val_accuracy: 0.5250 - val_loss: 0.8852\n",
      "Epoch 4/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.7161 - loss: 0.5720 - val_accuracy: 0.7250 - val_loss: 0.5924\n",
      "Epoch 5/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.6752 - loss: 0.5943 - val_accuracy: 0.7000 - val_loss: 0.5770\n",
      "Epoch 6/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.7492 - loss: 0.5216 - val_accuracy: 0.9000 - val_loss: 0.4420\n",
      "Epoch 7/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.8182 - loss: 0.4230 - val_accuracy: 0.9500 - val_loss: 0.3609\n",
      "Epoch 8/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.8276 - loss: 0.4139 - val_accuracy: 0.9500 - val_loss: 0.3447\n",
      "Epoch 9/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.8949 - loss: 0.3712 - val_accuracy: 0.9250 - val_loss: 0.3568\n",
      "Epoch 10/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.9157 - loss: 0.3416 - val_accuracy: 1.0000 - val_loss: 0.2913\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.2639\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.2941\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.2789\n",
      "Training accuracy: 1.0\n",
      "Validation accuracy: 1.0\n",
      "Testing accuracy: 1.0\n",
      "\n",
      "Training model with optimizer: sgd\n",
      "Epoch 1/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5155 - loss: 0.9032 - val_accuracy: 0.9750 - val_loss: 0.3744\n",
      "Epoch 2/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5760 - loss: 0.7229 - val_accuracy: 1.0000 - val_loss: 0.2465\n",
      "Epoch 3/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6337 - loss: 0.6554 - val_accuracy: 1.0000 - val_loss: 0.2698\n",
      "Epoch 4/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7255 - loss: 0.5584 - val_accuracy: 1.0000 - val_loss: 0.3594\n",
      "Epoch 5/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7145 - loss: 0.5529 - val_accuracy: 1.0000 - val_loss: 0.3064\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9766 - loss: 0.3335\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.3091 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.2874 \n",
      "Training accuracy: 0.984375\n",
      "Validation accuracy: 1.0\n",
      "Testing accuracy: 1.0\n",
      "\n",
      "Training model with optimizer: sgd_momentum\n",
      "Epoch 1/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.6182 - loss: 0.8447 - val_accuracy: 0.3250 - val_loss: 1.7123\n",
      "Epoch 2/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8800 - loss: 0.3516 - val_accuracy: 0.9250 - val_loss: 0.2600\n",
      "Epoch 3/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9572 - loss: 0.1641 - val_accuracy: 1.0000 - val_loss: 0.0333\n",
      "Epoch 4/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0812 - val_accuracy: 1.0000 - val_loss: 0.0265\n",
      "Epoch 5/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9992 - loss: 0.0565 - val_accuracy: 1.0000 - val_loss: 0.0241\n",
      "Epoch 6/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0383 - val_accuracy: 1.0000 - val_loss: 0.0137\n",
      "Epoch 7/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0295 - val_accuracy: 1.0000 - val_loss: 0.0121\n",
      "Epoch 8/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0246 - val_accuracy: 1.0000 - val_loss: 0.0097\n",
      "Epoch 9/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0195 - val_accuracy: 1.0000 - val_loss: 0.0084\n",
      "Epoch 10/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0194 - val_accuracy: 1.0000 - val_loss: 0.0070\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0068\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0070\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0070\n",
      "Training accuracy: 1.0\n",
      "Validation accuracy: 1.0\n",
      "Testing accuracy: 1.0\n",
      "\n",
      "Training model with optimizer: rmsprop\n",
      "Epoch 1/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.4627 - loss: 0.9401 - val_accuracy: 0.0250 - val_loss: 3.1697\n",
      "Epoch 2/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.6153 - loss: 0.7228 - val_accuracy: 0.0000e+00 - val_loss: 2.9987\n",
      "Epoch 3/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6909 - loss: 0.6232 - val_accuracy: 0.0000e+00 - val_loss: 2.5376\n",
      "Epoch 4/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.7310 - loss: 0.5468 - val_accuracy: 0.0250 - val_loss: 2.2885\n",
      "Epoch 5/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.7593 - loss: 0.4954 - val_accuracy: 0.0250 - val_loss: 1.4301\n",
      "Epoch 6/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.7900 - loss: 0.4336 - val_accuracy: 0.6500 - val_loss: 0.7103\n",
      "Epoch 7/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.8325 - loss: 0.4327 - val_accuracy: 0.6500 - val_loss: 0.5982\n",
      "Epoch 8/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.8743 - loss: 0.3506 - val_accuracy: 0.6500 - val_loss: 0.5436\n",
      "Epoch 9/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.9111 - loss: 0.2769 - val_accuracy: 0.9000 - val_loss: 0.3674\n",
      "Epoch 10/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.9448 - loss: 0.2525 - val_accuracy: 0.9500 - val_loss: 0.2933\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9845 - loss: 0.2726\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9458 - loss: 0.2998\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.2670 \n",
      "Training accuracy: 0.981249988079071\n",
      "Validation accuracy: 0.949999988079071\n",
      "Testing accuracy: 1.0\n",
      "\n",
      "Optimizer: adam\n",
      "Training accuracy: [1.0]\n",
      "Validation accuracy: [1.0]\n",
      "Testing accuracy: [1.0]\n",
      "\n",
      "Optimizer: sgd\n",
      "Training accuracy: [0.984375]\n",
      "Validation accuracy: [1.0]\n",
      "Testing accuracy: [1.0]\n",
      "\n",
      "Optimizer: sgd_momentum\n",
      "Training accuracy: [1.0]\n",
      "Validation accuracy: [1.0]\n",
      "Testing accuracy: [1.0]\n",
      "\n",
      "Optimizer: rmsprop\n",
      "Training accuracy: [0.981249988079071]\n",
      "Validation accuracy: [0.949999988079071]\n",
      "Testing accuracy: [1.0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "image_width = 150\n",
    "image_height = 150\n",
    "epochs = 10 \n",
    "# Define optimizers to compare\n",
    "optimizers = {\n",
    "    'adam': 'adam',\n",
    "    'sgd': SGD(),\n",
    "    'sgd_momentum': SGD(momentum=0.9),\n",
    "    'rmsprop': RMSprop(learning_rate=0.001)  \n",
    "}\n",
    "\n",
    "# Initialize lists to hold accuracies for each optimizer\n",
    "train_accuracies_opt = {opt_name: [] for opt_name in optimizers}\n",
    "valid_accuracies_opt = {opt_name: [] for opt_name in optimizers}\n",
    "test_accuracies_opt = {opt_name: [] for opt_name in optimizers}\n",
    "\n",
    "\n",
    "train_dir = '/home/bhumika-avadutha/Desktop/train'\n",
    "valid_dir = '/home/bhumika-avadutha/Desktop/valid'\n",
    "test_dir = '/home/bhumika-avadutha/Desktop/test'\n",
    "\n",
    "# Load and preprocess data for each dataset\n",
    "for opt_name, optimizer in optimizers.items():\n",
    "    print(f\"\\nTraining model with optimizer: {opt_name}\")\n",
    "    \n",
    "    # Load training data\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    train_files = [os.path.join(train_dir, file) for file in os.listdir(train_dir)]\n",
    "    for file in train_files:\n",
    "        img = load_img(file, target_size=(image_width, image_height))\n",
    "        img_array = img_to_array(img) / 255.0\n",
    "        train_images.append(img_array)\n",
    "        train_labels.append(1 if 'positive' in file else 0)  # Adjust label based on naming convention\n",
    "    train_images = np.array(train_images)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    # Load validation data\n",
    "    valid_images = []\n",
    "    valid_labels = []\n",
    "    valid_files = [os.path.join(valid_dir, file) for file in os.listdir(valid_dir)]\n",
    "    for file in valid_files:\n",
    "        img = load_img(file, target_size=(image_width, image_height))\n",
    "        img_array = img_to_array(img) / 255.0\n",
    "        valid_images.append(img_array)\n",
    "        valid_labels.append(1 if 'positive' in file else 0)  # Adjust label based on naming convention\n",
    "    valid_images = np.array(valid_images)\n",
    "    valid_labels = np.array(valid_labels)\n",
    "\n",
    "    # Load testing data\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "    test_files = [os.path.join(test_dir, file) for file in os.listdir(test_dir)]\n",
    "    for file in test_files:\n",
    "        img = load_img(file, target_size=(image_width, image_height))\n",
    "        img_array = img_to_array(img) / 255.0\n",
    "        test_images.append(img_array)\n",
    "        test_labels.append(1 if 'positive' in file else 0)  # Adjust label based on naming convention\n",
    "    test_images = np.array(test_images)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "    # Model definition\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(image_width, image_height, 3)),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_images, train_labels,\n",
    "        epochs=epochs,\n",
    "        batch_size=20,  # Mini-batch size\n",
    "        validation_data=(valid_images, valid_labels),\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on training data\n",
    "    train_loss, train_accuracy = model.evaluate(train_images, train_labels)\n",
    "    train_accuracies_opt[opt_name].append(train_accuracy)\n",
    "\n",
    "    # Evaluate the model on validation data\n",
    "    valid_loss, valid_accuracy = model.evaluate(valid_images, valid_labels)\n",
    "    valid_accuracies_opt[opt_name].append(valid_accuracy)\n",
    "\n",
    "    # Evaluate the model on testing data\n",
    "    test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "    test_accuracies_opt[opt_name].append(test_accuracy)\n",
    "\n",
    "    # Print accuracies\n",
    "    print(f'Training accuracy: {train_accuracy}')\n",
    "    print(f'Validation accuracy: {valid_accuracy}')\n",
    "    print(f'Testing accuracy: {test_accuracy}')\n",
    "\n",
    "# Print final results\n",
    "for opt_name in optimizers:\n",
    "    print(f\"\\nOptimizer: {opt_name}\")\n",
    "    print(f\"Training accuracy: {train_accuracies_opt[opt_name]}\")\n",
    "    print(f\"Validation accuracy: {valid_accuracies_opt[opt_name]}\")\n",
    "    print(f\"Testing accuracy: {test_accuracies_opt[opt_name]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c306ef-e348-4405-be25-c5d2472a3255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multilayer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98fdb469-8b97-4905-b4e0-9b10896fc30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6978 - loss: 1.1331 - val_accuracy: 0.9296 - val_loss: 0.2554\n",
      "Epoch 2/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9344 - loss: 0.2366 - val_accuracy: 0.9502 - val_loss: 0.1817\n",
      "Epoch 3/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9509 - loss: 0.1694 - val_accuracy: 0.9554 - val_loss: 0.1556\n",
      "Epoch 4/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9622 - loss: 0.1335 - val_accuracy: 0.9550 - val_loss: 0.1491\n",
      "Epoch 5/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9674 - loss: 0.1136 - val_accuracy: 0.9637 - val_loss: 0.1221\n",
      "Epoch 6/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9729 - loss: 0.0947 - val_accuracy: 0.9647 - val_loss: 0.1155\n",
      "Epoch 7/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9785 - loss: 0.0782 - val_accuracy: 0.9682 - val_loss: 0.1080\n",
      "Epoch 8/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.0647 - val_accuracy: 0.9708 - val_loss: 0.0968\n",
      "Epoch 9/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9855 - loss: 0.0545 - val_accuracy: 0.9705 - val_loss: 0.0954\n",
      "Epoch 10/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9877 - loss: 0.0469 - val_accuracy: 0.9727 - val_loss: 0.0911\n",
      "Epoch 11/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9902 - loss: 0.0393 - val_accuracy: 0.9721 - val_loss: 0.0918\n",
      "Epoch 12/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9910 - loss: 0.0348 - val_accuracy: 0.9744 - val_loss: 0.0851\n",
      "Epoch 13/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9931 - loss: 0.0297 - val_accuracy: 0.9756 - val_loss: 0.0828\n",
      "Epoch 14/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9940 - loss: 0.0259 - val_accuracy: 0.9759 - val_loss: 0.0840\n",
      "Epoch 15/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9958 - loss: 0.0199 - val_accuracy: 0.9771 - val_loss: 0.0824\n",
      "Epoch 16/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9961 - loss: 0.0181 - val_accuracy: 0.9756 - val_loss: 0.0844\n",
      "Epoch 17/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9967 - loss: 0.0156 - val_accuracy: 0.9774 - val_loss: 0.0828\n",
      "Epoch 18/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9982 - loss: 0.0121 - val_accuracy: 0.9758 - val_loss: 0.0871\n",
      "Epoch 19/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9981 - loss: 0.0109 - val_accuracy: 0.9778 - val_loss: 0.0834\n",
      "Epoch 20/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9987 - loss: 0.0087 - val_accuracy: 0.9779 - val_loss: 0.0864\n",
      "Epoch 21/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9987 - loss: 0.0078 - val_accuracy: 0.9772 - val_loss: 0.0880\n",
      "Epoch 22/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9992 - loss: 0.0066 - val_accuracy: 0.9767 - val_loss: 0.0902\n",
      "Epoch 23/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9994 - loss: 0.0055 - val_accuracy: 0.9777 - val_loss: 0.0875\n",
      "Epoch 24/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 0.0037 - val_accuracy: 0.9781 - val_loss: 0.0905\n",
      "Epoch 25/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0033 - val_accuracy: 0.9779 - val_loss: 0.0903\n",
      "Epoch 26/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 0.0024 - val_accuracy: 0.9779 - val_loss: 0.0971\n",
      "Epoch 27/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9776 - val_loss: 0.0976\n",
      "Epoch 28/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9768 - val_loss: 0.0996\n",
      "Epoch 29/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9980 - loss: 0.0070 - val_accuracy: 0.9768 - val_loss: 0.0987\n",
      "Test accuracy: 0.9794\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Load MNIST data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Preprocess data\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = train_images[0].shape\n",
    "num_classes = 10  # Since MNIST has 10 classes (digits 0-9)\n",
    "\n",
    "# Build the model without dropout\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=input_shape),           # Flatten input to 1D\n",
    "    Dense(512, activation='relu'),              # Hidden layer with 512 neurons, ReLU activation\n",
    "    Dense(256, activation='relu'),              \n",
    "    Dense(128, activation='relu'),              \n",
    "    Dense(num_classes, activation='softmax')    # Output layer with softmax activation for classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),   # Optimizer with lower learning rate\n",
    "              loss=SparseCategoricalCrossentropy(),  # Loss function for multi-class classification\n",
    "              metrics=['accuracy'])                 # Metrics to monitor during training\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Training\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    epochs=50,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=1)\n",
    "\n",
    "# Evaluate on test data\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(f'Test accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce05c80-904b-4072-b707-46ace14cfe0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
